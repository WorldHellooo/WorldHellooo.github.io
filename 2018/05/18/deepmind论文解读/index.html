<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>DeepMind论文：连接多巴胺与元强化学习的新方法 | WorldHellooo's Blog</title><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/5.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/0.6.2/grids-responsive-min.css"><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.1.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">DeepMind论文：连接多巴胺与元强化学习的新方法</h1><a id="logo" href="/.">WorldHellooo's Blog</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a></div></div><div id="layout" class="pure-g"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">DeepMind论文：连接多巴胺与元强化学习的新方法</h1><div class="post-meta">May 18, 2018<span> | </span><span class="category"><a href="/categories/GUI/">GUI</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> Hits</span></span></div><div class="post-content"><h2 id="ABSTRACT"><a href="#ABSTRACT" class="headerlink" title="ABSTRACT"></a>ABSTRACT</h2><p>过去20年间，神经科学中对于Reward-based Learning的研究已经收敛到了一类规范的模式上：神经递质多巴胺通过调整神经元之间的突触连接强度，以在情景、动作和奖励之间建立关联。但是，近期越来越多的发现开始挑战这一标准模型。因此，本文提出一种新的基于奖励的学习机制：多巴胺系统训练了另一个大脑区域————前额叶，来将其作为独立的学习系统。这个全新的视角既能够继承标准模型的那些依据，也能够很好地处理宽泛的经验观察，为未来的研究提供全新的基础。</p>
<h2 id="关键名词缩写"><a href="#关键名词缩写" class="headerlink" title="关键名词缩写"></a>关键名词缩写</h2><table>
<thead>
<tr>
<th style="text-align:left">全称</th>
<th style="text-align:left">中文翻译</th>
<th style="text-align:left">缩写</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">reinforcement learning</td>
<td style="text-align:left">强化学习</td>
<td style="text-align:left">RL</td>
</tr>
<tr>
<td style="text-align:left">dopamine</td>
<td style="text-align:left">多巴胺</td>
<td style="text-align:left">DA</td>
</tr>
<tr>
<td style="text-align:left">reward prediction error</td>
<td style="text-align:left">奖励预测误差</td>
<td style="text-align:left">RPE</td>
</tr>
<tr>
<td style="text-align:left">prefrontal cortex</td>
<td style="text-align:left">前额皮质</td>
<td style="text-align:left">PFC</td>
</tr>
</tbody>
</table>
<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在现有的认知中，DA被认为是强化学习中的RPE，即奖励信号。在这个理论中，RPR驱动突触的可塑性，将经验中得到的action-reward关联性转换成优化后的行为策略。但是这一理论正面临挑战。其中一个质疑正来自于对于PFC的研究。<br>近期研究表明，PFC不仅表示了actions、objects和states的期望，还编码了近期actions和rewards的历史信息。PFC中的神经元动态地完成从rewards和choice history到object value的转换。这表明了PFC的神经元活动是一组独立的强化学习过程。<br>将PFC和DA分开考虑，我们得到了一个包含两个完整RL系统的图景，其中一个系统（PFC）利用activity-based representations，另一个系统（DA）利用突触学习。那么这两个系统之间是怎样的关系，它们的功能是否重叠冗余？一种假设是DA和PFC服务于不同形式的学习，DA实行<strong>model-free</strong>的强化学习，基于直接的刺激-响应关联；PFC实行<strong>model-based</strong>的强化学习，利用任务结构的内部表达。</p>
<h2 id="三个关键前提"><a href="#三个关键前提" class="headerlink" title="三个关键前提"></a>三个关键前提</h2><h3 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h3><p>使用循环神经网络来建模PFC。</p>
<h3 id="学习过程"><a href="#学习过程" class="headerlink" title="学习过程"></a>学习过程</h3><p>我们假设一个由DA传达的RPE信号控制的model-free强化学习过程，负责调节前额网络中的所有突触权重。通过这一途径，DA-based RL过程塑造了循环前额网络的activation dynamics。</p>
<h3 id="任务环境"><a href="#任务环境" class="headerlink" title="任务环境"></a>任务环境</h3><p>我们设定任务环境中同时有多个内在关联的任务。学习系统需要进行持续的推理和行为调整。</p>
</div><script type="text/javascript" src="/js/share.js?v=0.0.0" async></script><a data-url="http://worldhellooo.github.io/2018/05/18/deepmind论文解读/" data-id="cjpkx3imz001awosefdlf8iwv" class="article-share-link">分享到</a><div class="tags"></div><div class="post-nav"><a href="/2018/12/12/关于概率和熵的一些概念/" class="pre">关于概率和熵的一些概念</a><a href="/2018/04/26/pytorch doc阅读笔记/" class="next">pytorch doc阅读笔记</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank" class="search-form"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="http://worldhellooo.github.io"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Computer-Vision/">Computer Vision</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Deep-Learning/">Deep Learning</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/GUI/">GUI</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Reinforcement-Learing/">Reinforcement Learing</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Visual-Tracking/">Visual Tracking</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/competition/">competition</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/笔记/">笔记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/实例搜索-孪生结果-目标追踪/" style="font-size: 15px;">实例搜索 孪生结果 目标追踪</a> <a href="/tags/增强学习-目标追踪/" style="font-size: 15px;">增强学习 目标追踪</a> <a href="/tags/目标追踪/" style="font-size: 15px;">目标追踪</a> <a href="/tags/增强学习/" style="font-size: 15px;">增强学习</a> <a href="/tags/目标追踪-研究背景-主流思路/" style="font-size: 15px;">目标追踪 研究背景 主流思路</a> <a href="/tags/RoIPooling-翻译/" style="font-size: 15px;">RoIPooling 翻译</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最新文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/12/12/关于概率和熵的一些概念/">关于概率和熵的一些概念</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/05/18/deepmind论文解读/">DeepMind论文：连接多巴胺与元强化学习的新方法</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/26/pytorch doc阅读笔记/">pytorch doc阅读笔记</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/18/大数据竞赛经验谈/">大数据竞赛经验谈</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/12/基于PyQt的多源图像文字描述生成软件界面/">基于PyQt的多源图像文字描述生成软件界面</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/翻译 Region of interest pooling explained/">翻译 Region of interest pooling explained</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/深度网络训练中的一些参数/">深度网络训练中的一些技巧</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/目标追踪经典算法系列/">目标追踪算法之研究背景</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/SINT/">Introduction of Siamese Instance Search for Tracking</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/04/08/SiamFC改进思路/">SiamFC算法改进思路</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://blog.jcix.top" title="Zhangjc's blog" target="_blank">Zhangjc's blog</a><ul></ul><a href="http://chaway.github.io" title="Chaway's blog" target="_blank">Chaway's blog</a><ul></ul><a href="http://www.votchallenge.net" title="VOT Challenge" target="_blank">VOT Challenge</a><ul></ul><a href="http://www.visual-tracking.net" title="OTB Benchmark" target="_blank">OTB Benchmark</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">© <a href="/." rel="nofollow">WorldHellooo's Blog.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a id="rocket" href="#top" class="show"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.pack.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="/css/jquery.fancybox.css?v=0.0.0"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>